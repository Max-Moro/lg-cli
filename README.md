# Listing Generator

Инструмент для сборки «плотных» контекстов из исходников: обходит проект, фильтрует и нормализует файлы, а затем собирает из них один аккуратный Markdown-документ — идеально подходящий для ChatGPT/Copilot/Gemini/Claude и других LLM-ассистентов.

> Коротко: вы храните правила отбора в `lg-cfg/` (YAML + шаблоны контекстов), а LG рендерит «готовый к вставке» текст или возвращает JSON-отчёт со статистикой токенов.

---

## Зачем это и для кого

**Категория пользователей:** разработчики, тимлиды и техписы, которые ведут диалоги с AI-агентами по реальному коду, делают ревью, выдают задания, фиксируют контекст итераций, а окно модели — ограничено.

**Зачем:** современные агенты работают заметно лучше, когда видят **ровно нужный код** и **минимум шума**: никакого мусора из `node_modules/`, логов, сгенерированных файлов, огромных бинарников и т. п. Ручная подготовка такого контекста — боль. LG автоматизирует:

* выбор релевантных файлов (по фильтрам и расширениям),
* лёгкую нормализацию (напр., Markdown-заголовки, «тривиальные» `__init__.py`),
* склейку в один документ с **видимыми метками файлов**,
* учёт `.gitignore`,
* **режим `changes`** (только изменённые файлы),
* **шаблоны и контексты** (вставки секций и вложенные шаблоны),
* оценку размера/токенов и долей («кто ест промт»).

Существует множество способов формирования промтов и прикладывания к ним нужных участков кода: начиная от ручного копирования и заканчивая функциями формирования контекстных вложений в IDE с интегрированными AI-чатами. LG отличается тем, что делает это **системно и воспроизводимо**: правила хранятся в репозитории, а не в голове или истории диалога с AI-агентом.

Вы заранее описываете, **что** и **как** попадёт в промт (через секции и шаблоны). Это дисциплинирует, позволяет «подкручивать» плотность и **не вываливать модель за окно**, а также воспроизводить успешные запросы через сохранённые шаблоны.

---

## Как выглядит «здоровый» процесс с AI-агентом

1. **Опишите правила в репозитории**
   Создайте `lg-cfg/sections.yaml` и при необходимости дополнительные `*.sec.yaml`. В них описываются секции (наборы файлов + фильтры). Для шаблонов и контекстов используйте `*.tpl.md` и `*.ctx.md`.

2. **Соберите контекст**
   Рендерите: или «секцию» (виртуальный контекст одного набора файлов), или «контекст» (шаблон, который может включать несколько секций и других шаблонов).

3. **Итеративно ужимайте**
   Смотрите на статистику токенов (у кого «самая тяжёлая доля»), выносите второстепенное в отдельные секции, подключайте по требованию. Для «малых апдейтов» используйте `--mode changes`.

4. **Фиксируйте удачные промты**
   Контексты и шаблоны (`*.ctx.md` и `*.tpl.md`) — это ваши «хорошо работающие» форматы запросов: можно воспроизводить, версионировать, делать варианты для разных задач и агентов.

---

## Быстрый старт

### Установка и запуск

Минимально нужен Python ≥ 3.10.
Зависимости рантайма: `ruamel.yaml`, `pathspec`.
Для JSON-отчёта со статистикой (`report`) нужен `tiktoken`.

Варианты запуска:

```bash
# 1) Без установки — модуль напрямую
python -m lg.cli render sec:core > prompt.md

# 2) Установка в editable-режиме (если у вас есть pyproject.toml)
pip install -e ./lg
lg render sec:core > prompt.md      # если настроен console_script "lg"
```

Проверка окружения и кэша:

```bash
python -m lg.cli diag
python -m lg.cli diag --rebuild-cache
```

---

## Что положить в `lg-cfg/`

> Важно: каталог конфигурации всегда называется **`lg-cfg/`**.

Пример структуры:

```
lg-cfg/
├─ sections.yaml           # основной YAML с секциями (обязателен)
├─ additional.sec.yaml     # дополнительный набор секций (может быть много)
├─ intro.tpl.md            # шаблон (может быть много, в любых подпапках)
├─ onboarding.ctx.md       # контекст (может быть много, в любых подпапках)
└─ sub-fold/
   └─ extra.sec.yaml
```

### Секции

* `sections.yaml` — файл с базовыми секциями.
* `*.sec.yaml` — дополнительные наборы секций (фрагменты). В них версия опциональна.

Секция описывает:

* расширения файлов, которые рассматривать,
* фильтры allow/block по дереву,
* политику для пустых файлов, code-fence и адаптеров языков.

Минимальный пример:

```yaml
# Секция для документации по проекту
docs:
  extensions: [".md"]
  markdown:
    # Нормализовать заголовки до H2 (вне fenced-блоков), одиночный H1 в начале — удалить
    max_heading_level: 2
  filters:
    mode: allow            # default-deny внутри секции
    allow:
      - "/README.md"
      - "/docs/**"

# Исходники подмодуля core-model
core-model-src:
  extensions: [".py", ".md", ".yaml", ".json", ".toml"]
  skip_empty: true
  python:
    skip_trivial_inits: true
  markdown:
    max_heading_level: 3
  filters:
    mode: allow
    allow:
      - "/core-model/**"
    children:
      core-model:
        mode: block
        block:
          - "**/.pytest_cache/**"
          - "/ROADMAP.md"

# Отдельная секция для дорожной карты (как текст)
core-model-roadmap:
  extensions: [".md"]
  filters:
    mode: allow
    allow:
      - "/core-model/ROADMAP.md"
```

### Фильтры: как они работают

* Дерево правил — **default-allow** (`mode: block`) или **default-deny** (`mode: allow`).
* На каждом уровне: сначала `block`, потом (если узел `allow`) — **жёсткая** проверка на `allow`.
  Если `mode: allow` и путь не совпал с локальным `allow`, он **сразу отбрасывается**.
* `block` всегда сильнее `allow`.
* Учитывается `.gitignore` проекта.
* LG также бережно **не спускается** в поддеревья, которые точно ничего не дадут (ранний pruner).

### Контексты и шаблоны

* Контексты: `*.ctx.md` (верхнеуровневые документы).
* Шаблоны: `*.tpl.md` (фрагменты для вставки).

Пример:

```markdown
# Вводная по проекту

${tpl:intro}

## Исходный код модуля core-model

${core-model-src}

## Доп. секция

${sub-fold/extra/bar}
```

Секции из `sections.yaml` доступны напрямую (`${docs}`),
а из фрагментов — по иерархическому пути:
файл `sub-fold/extra.sec.yaml` → секция `bar` → `${sub-fold/extra/bar}`.

*Подробнее:* [docs/templates.md](docs/templates.md).

---

## Языковые адаптеры

Listing Generator использует адаптеры для разных языков и форматов. Они помогают «оптимизировать» листинг: убирать мусор, нормализовать заголовки, фильтровать параграфы или даже вырезать тела функций, оставляя только сигнатуры. Настройки адаптеров задаются прямо в YAML секций — глобально для секции или адресно для отдельных путей через `targets`.

### Пример конфигурации

```yaml
core:
  extensions: [".py", ".md"]
  skip_empty: true

  # Глобальные правила для всей секции
  python:
    skip_trivial_inits: true
    strip_function_bodies: false

  markdown:
    max_heading_level: 2

  # Локальные оверрайды для отдельных папок и файлов
  targets:
    - match: "/pkg/**.py"
      python:
        strip_function_bodies: true      # только сигнатуры в этой папке

    - match: ["/docs/**.md", "/notes/*.md"]
      markdown:
        drop:
          sections:
            - match: { kind: regex, pattern: "^(License|Changelog|Contributing)$", flags: "i" }
```

В этом примере секция `core` описывает сразу два языка. Для Python глобально отключено вырезание тел функций, но внутри папки `/pkg/` оно включено. Для Markdown выставлен общий уровень заголовков, но в `/docs/` и `/notes/` будут дополнительно фильтроваться параграфы по заданным шаблонам.

Ключ `match` принимает либо строку, либо массив glob-шаблонов. При совпадении нескольких правил выигрывает более специфичный (длиннее и конкретнее), при равенстве — более поздний в списке. Это позволяет аккуратно накладывать локальные «оверрайды» поверх секционных настроек.

Отдельная политика пустых файлов (`skip_empty` на уровне секции и `empty_policy` в адаптерах) работает так же, будто это часть языковых опций: секция задаёт общую стратегию, а адаптер при необходимости может её уточнить. Возможные варианты: `empty_policy: inherit|include|exclude`.


---

### Уже доступные адаптеры

#### Markdown

* Нормализовать заголовки (снять одинокий H1, сдвинуть уровни).
* Системно **вырезать целые разделы** по заголовкам (с поддеревом).

* Снести **YAML front matter** в начале.
* Вставить **плейсхолдеры** на месте удалённого (по желанию).

*Подробнее:* [docs/markdown.md](docs/markdown.md).

#### Языки программирования

*Подробнее:* [docs/adapters.md](docs/adapters.md).

---

## Статистика по токенам

Для облегчения процесса оптимизации листингов и контекстов LG позволяет получать сводный отчет по используемым токенам применимо к конкретной AI-модели. 

*Подробнее:* [docs/models.md](docs/models.md).

---

## Адаптивные возможности

Все способы создания универсальных шаблонов и конфигураций секций описаны в разделе [Адаптивные возможности](docs/adaptability.md).

---

## CLI-опции

Общий формат:

```
lg <command> <target> [--mode all|changes] [<additional_flags>]
```

Где `<target>`:

* `ctx:<name>` — берётся файл `lg-cfg/<name>.ctx.md` (поддерживаются подпапки).
* `sec:<id>` — виртуальный контекст одной секции (канонический ID).
* `<name>` — сначала ищется как `ctx:<name>`, иначе как `sec:<id>`.

Команды:

* `render` — вывести **только финальный текст** (Markdown).
* `report` — **JSON-отчёт** (формат v4): статистика, файлы, контекстный блок.
* `list contexts|sections` — перечисление доступных сущностей (JSON).
* `diag` — диагностика окружения/кэша/конфига (JSON), есть `--rebuild-cache`.

Примеры:

```bash
# Рендерим контекст из шаблона
lg render ctx:onboarding > prompt.md

# Рендерим «только секцию» (без шаблона)
lg render sec:core-model-src > prompt.md

# То же, но только изменённые файлы рабочего дерева
lg render ctx:onboarding --mode changes > prompt.md

# JSON-отчёт со статистикой токенов для выбранной модели
lg report onboarding --model gpt-4o > report.json

# Диагностика
lg diag
lg diag --rebuild-cache

# Списки
lg list contexts
lg list sections
```

Пара полезных флагов:

* `--mode changes` — берёт `staged + unstaged + untracked` (нужен `git`).
* `--no-fence` — форс-отключение code fences на выходе (поведение секций переопределяется).
* `--model` — выбирает энкодер/лимит окна для расчёта токенов (`tiktoken` обязателен для `report`).

---

## Как именно LG рендерит документы

* Если **все файлы — Markdown/plain**, LG просто конкатенирует их содержимое.
* В остальных случаях:

  * **с code-fence** (по умолчанию): блоки по языкам, сгруппированные **по порядку следования**;
    внутри каждого блока — маркер файла `# —— FILE: path ——`, затем содержимое.
  * **без code-fence**: линейный документ с маркером перед каждым файлом.

Это делает промт **читаемым** для человека и удобным для агентов: видно, откуда какой фрагмент.

---

## Кэш и производительность

LG использует файловый кэш `.lg-cache`:

* **Processed-кэш** — результат работы адаптеров + их метаданные.
* **Raw/Processed tokens** — сохранённые подсчёты токенов (по модели/режиму).
* **Rendered tokens** — подсчёт финального документа («с клеем») и «sections-only».

Ключи кэша учитывают версию инструмента, fingerprint файла, конфиг адаптера, состав групп и т. п.
Управление: `lg diag`, `lg diag --rebuild-cache`. Можно отключить кэш через `LG_CACHE=0`.

---

## Практические советы по «плотным» контекстам

* **Держите секции мелкими и тематическими.** Лучше несколько секций, чем одна «всё обо всём».
* **Жёсткие `allow`-узлы** используйте там, где нужна полная предсказуемость содержимого.
* **Markdown-шаблоны** применяйте как «рамку» промта: краткая вводная, задачи, place-holders секций.
* **Режим `changes`** — лучший друг для патч-итераций и code-review через LLM.
* **Следите за долями** (`promptShare`/`ctxShare`) в `report`: это помогает «холдинг-кост» распределять.
* **Нормализуйте заголовки** (`max_heading_level`) — так удобнее читать длинные контексты.
* **Не тащите секреты.** Настройте `block` для артефактов/ключей/секретов/бинарников.

---

## Интеграция с IDE/плагинами

В большинстве случаев вы будете запускать LG **через интеграцию** (VS Code / JetBrains и т. п.).
Тем не менее, **вся логика отбора/шаблонов лежит в репозитории** (`lg-cfg/`), поэтому:

* ревьюить и эволюционировать правила просто (PR-ами),
* переносить удачные промты между проектами — тривиально,
* одна и та же конфигурация работает в CLI и в IDE.