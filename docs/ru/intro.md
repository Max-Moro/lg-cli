# Listing Generator

Инструмент для сборки «плотных» контекстов из исходников: обходит проект, фильтрует и нормализует файлы, а затем собирает из них один аккуратный Markdown-документ — идеально подходящий для ChatGPT/Copilot/Gemini/Claude и других LLM-ассистентов.

> Коротко: вы храните правила отбора в `lg-cfg/` (YAML + шаблоны контекстов), а LG рендерит «готовый к вставке» текст или возвращает JSON-отчёт со статистикой токенов.

---

## Зачем это и для кого

**Категория пользователей:** разработчики, тимлиды и техписы, которые ведут диалоги с AI-агентами по реальному коду, делают ревью, выдают задания, фиксируют контекст итераций, а окно модели — ограничено.

**Зачем:** современные агенты работают заметно лучше, когда видят **ровно нужный код** и **минимум шума**: никакого мусора из `node_modules/`, логов, сгенерированных файлов, огромных бинарников и т. п. Ручная подготовка такого контекста — боль. LG автоматизирует:

* выбор релевантных файлов (по фильтрам и расширениям),
* лёгкую нормализацию (напр., Markdown-заголовки, «тривиальные» `__init__.py`),
* склейку в один документ с **видимыми метками файлов**,
* учёт `.gitignore`,
* **режим `changes`** (только изменённые файлы),
* **шаблоны и контексты** (вставки секций и вложенные шаблоны),
* оценку размера/токенов и долей («кто ест промт»).

Существует множество способов формирования промтов и прикладывания к ним нужных участков кода: начиная от ручного копирования и заканчивая функциями формирования контекстных вложений в IDE с интегрированными AI-чатами. LG отличается тем, что делает это **системно и воспроизводимо**: правила хранятся в репозитории, а не в голове или истории диалога с AI-агентом.

Вы заранее описываете, **что** и **как** попадёт в промт (через секции и шаблоны). Это дисциплинирует, позволяет «подкручивать» плотность и **не вываливать модель за окно**, а также воспроизводить успешные запросы через сохранённые шаблоны.

---

## Как выглядит «здоровый» процесс с AI-агентом

1. **Опишите правила в репозитории**
   Создайте `lg-cfg/sections.yaml` и при необходимости дополнительные `*.sec.yaml`. В них описываются секции (наборы файлов + фильтры). Для шаблонов и контекстов используйте `*.tpl.md` и `*.ctx.md`.

2. **Соберите контекст**
   Рендерите: или «секцию» (виртуальный контекст одного набора файлов), или «контекст» (шаблон, который может включать несколько секций и других шаблонов).

3. **Итеративно ужимайте**
   Смотрите на статистику токенов (у кого «самая тяжёлая доля»), выносите второстепенное в отдельные секции, подключайте по требованию. Для «малых апдейтов» используйте `--mode changes`.

4. **Фиксируйте удачные промты**
   Контексты и шаблоны (`*.ctx.md` и `*.tpl.md`) — это ваши «хорошо работающие» форматы запросов: можно воспроизводить, версионировать, делать варианты для разных задач и агентов.

---

## Быстрый старт

### Установка и запуск

Минимально нужен Python ≥ 3.10.

Установка:

```bash
# Установка из директории с проектом
pip install -e .
```

Проверка:

```bash
# Проверка через модуль
python -m lg.cli --version

# Или через установленную команду
listing-generator --version
```

Проверка окружения и кэша:

```bash
python -m lg.cli diag
python -m lg.cli diag --rebuild-cache
```

---

## Что положить в `lg-cfg/`

> Важно: каталог конфигурации всегда называется **`lg-cfg/`**.

Пример структуры:

```
lg-cfg/
├─ sections.yaml           # файл секций (может быть в любой директории)
├─ additional.sec.yaml     # дополнительный набор секций (может быть много)
├─ intro.tpl.md            # шаблон (может быть много, в любых подпапках)
├─ onboarding.ctx.md       # контекст (может быть много, в любых подпапках)
└─ sub-fold/
   ├─ sections.yaml        # еще один sections.yaml (секции получат префикс sub-fold/)
   └─ extra.sec.yaml
```

### Секции

* `sections.yaml` — файл с секциями. Может быть в корне `lg-cfg/` и в любых поддиректориях.
  - В корне: секции без префикса (например, `docs`, `src`)
  - В поддиректориях: секции с префиксом директории (например, `adapters/src` из `lg-cfg/adapters/sections.yaml`)
* `*.sec.yaml` — дополнительные наборы секций (фрагменты).

Секция описывает:

* расширения файлов, которые рассматривать,
* фильтры allow/block по дереву,
* политику для пустых файлов, code-fence и адаптеров языков.

Минимальный пример:

```yaml
# Секция для документации по проекту
docs:
  extensions: [".md"]
  markdown:
    # Нормализовать заголовки до H2 (вне fenced-блоков), одиночный H1 в начале — удалить
    max_heading_level: 2
  filters:
    mode: allow            # default-deny внутри секции
    allow:
      - "/README.md"
      - "/docs/**"

# Исходники подмодуля core-model
core-model-src:
  extensions: [".py", ".md", ".yaml", ".json", ".toml"]
  skip_empty: true
  markdown:
    max_heading_level: 3
  filters:
    mode: allow
    allow:
      - "/core-model/**"
    children:
      core-model:
        mode: block
        block:
          - "**/.pytest_cache/**"
          - "/ROADMAP.md"

# Отдельная секция для дорожной карты (как текст)
core-model-roadmap:
  extensions: [".md"]
  filters:
    mode: allow
    allow:
      - "/core-model/ROADMAP.md"
```

### Фильтры: как они работают

* Дерево правил — **default-allow** (`mode: block`) или **default-deny** (`mode: allow`).
* На каждом уровне: сначала `block`, потом (если узел `allow`) — **жёсткая** проверка на `allow`.
  Если `mode: allow` и путь не совпал с локальным `allow`, он **сразу отбрасывается**.
* `block` всегда сильнее `allow`.
* Учитывается `.gitignore` проекта.
* LG также бережно **не спускается** в поддеревья, которые точно ничего не дадут (ранний pruner).

### Контексты и шаблоны

* Контексты: `*.ctx.md` (верхнеуровневые документы).
* Шаблоны: `*.tpl.md` (фрагменты для вставки).

Пример:

```markdown
# Вводная по проекту

${tpl:intro}

## Исходный код модуля core-model

${core-model-src}

## Доп. секция

${sub-fold/extra/bar}

## Текущая задача

${task}
```

Секции из корневого `lg-cfg/sections.yaml` доступны напрямую (`${docs}`).
Секции из `sections.yaml` в поддиректориях имеют префикс директории (например, `${adapters/src}` из `lg-cfg/adapters/sections.yaml`).
Фрагменты используют иерархические пути: файл `sub-fold/extra.sec.yaml` → секция `bar` → `${sub-fold/extra/bar}`.

**Контекстно-зависимые ссылки**: Из шаблонов в поддиректориях можно использовать короткие имена.
Пример: из `lg-cfg/adapters/overview.ctx.md` можно писать `${src}`, и это разрешится в `adapters/src`.

Специальный плейсхолдер `${task}` вставляет текст из аргумента `--task`:
* `${task}` — простая вставка (пустая строка если не задано)
* `${task:prompt:"дефолтный текст"}` — с дефолтным значением
* `{% if task %}...{% endif %}` — условная вставка блока

*Подробнее:* [templates.md](templates.md).

---

## Языковые адаптеры

Listing Generator использует адаптеры для разных языков и форматов. Они помогают «оптимизировать» листинг: убирать мусор, нормализовать заголовки, фильтровать параграфы или даже вырезать тела функций, оставляя только сигнатуры. Настройки адаптеров задаются прямо в YAML секций — глобально для секции или адресно для отдельных путей через `targets`.

### Пример конфигурации

```yaml
core:
  extensions: [".py", ".md"]
  skip_empty: true

  # Глобальные правила для всей секции
  python:
    strip_function_bodies: false

  markdown:
    max_heading_level: 2

  # Локальные оверрайды для отдельных папок и файлов
  targets:
    - match: "/pkg/**.py"
      python:
        strip_function_bodies: true      # только сигнатуры в этой папке

    - match: ["/docs/**.md", "/notes/*.md"]
      markdown:
        drop:
          sections:
            - match: { kind: regex, pattern: "^(License|Changelog|Contributing)$", flags: "i" }
```

В этом примере секция `core` описывает сразу два языка. Для Python глобально отключено вырезание тел функций, но внутри папки `/pkg/` оно включено. Для Markdown выставлен общий уровень заголовков, но в `/docs/` и `/notes/` будут дополнительно фильтроваться параграфы по заданным шаблонам.

Ключ `match` принимает либо строку, либо массив glob-шаблонов. При совпадении нескольких правил выигрывает более специфичный (длиннее и конкретнее), при равенстве — более поздний в списке. Это позволяет аккуратно накладывать локальные «оверрайды» поверх секционных настроек.

Отдельная политика пустых файлов (`skip_empty` на уровне секции и `empty_policy` в адаптерах) работает так же, будто это часть языковых опций: секция задаёт общую стратегию, а адаптер при необходимости может её уточнить. Возможные варианты: `empty_policy: inherit|include|exclude`.


---

### Уже доступные адаптеры

#### Markdown

* Нормализовать заголовки (снять одинокий H1, сдвинуть уровни).
* Системно **вырезать целые разделы** по заголовкам (с поддеревом).

* Снести **YAML front matter** в начале.
* Вставить **плейсхолдеры** на месте удалённого (по желанию).

*Подробнее:* [markdown.md](markdown.md).

#### Языки программирования

*Подробнее:* [adapters.md](adapters.md).

---

## Статистика по токенам

Для облегчения процесса оптимизации листингов и контекстов LG позволяет получать сводный отчет по используемым токенам. 

LG поддерживает несколько опенсорсных библиотек токенизации (tiktoken, tokenizers, sentencepiece) и требует явного указания параметров токенизации при каждом запуске.

*Подробнее:* [tokenizers.md](tokenizers.md).

---

## Адаптивные возможности

Все способы создания универсальных шаблонов и конфигураций секций описаны в разделе [Адаптивные возможности](adaptability.md).
<!-- lg:comment:start -->
---

## CLI-опции

Общий формат:

```bash
listing-generator <command> <target> [--mode MODESET:MODE] [--tags TAG1,TAG2] [<additional_flags>]

# Для render/report обязательны параметры токенизации:
listing-generator render|report <target> \
  --lib <tiktoken|tokenizers|sentencepiece> \
  --encoder <encoder_name> \
  --ctx-limit <tokens>
```

Где `<target>`:

* `ctx:<name>` — берётся файл `lg-cfg/<name>.ctx.md` (поддерживаются подпапки).
* `sec:<id>` — виртуальный контекст одной секции (канонический ID).
* `<name>` — сначала ищется как `ctx:<name>`, иначе как `sec:<id>`.

Команды:

* `render` — вывести **только финальный текст** (Markdown).
* `report` — **JSON-отчёт** (формат v5): статистика, файлы, контекстный блок.
* `list contexts|sections|tokenizer-libs|encoders` — перечисление доступных сущностей (JSON).
* `diag` — диагностика окружения/кэша/конфига (JSON), есть `--rebuild-cache`.

Параметры токенизации:

* `--lib` — библиотека токенизации (`tiktoken`, `tokenizers`, `sentencepiece`)
* `--encoder` — имя энкодера/модели (например: `cl100k_base`, `gpt2`, `google/gemma-2-2b`)
* `--ctx-limit` — размер контекстного окна в токенах (например: `128000`, `200000`)

Примеры:

```bash
# Рендерим контекст из шаблона с токенизацией для GPT-4
listing-generator render ctx:onboarding \
  --lib tiktoken \
  --encoder cl100k_base \
  --ctx-limit 128000 > prompt.md

# Рендерим «только секцию» (без шаблона)
listing-generator render sec:core-model-src \
  --lib tiktoken \
  --encoder cl100k_base \
  --ctx-limit 128000 > prompt.md

# То же, но только изменённые файлы рабочего дерева
listing-generator render ctx:onboarding \
  --lib tiktoken \
  --encoder cl100k_base \
  --ctx-limit 128000 \
  --mode vcs:branch-changes > prompt.md

# JSON-отчёт со статистикой токенов для GPT-4o
listing-generator report ctx:onboarding \
  --lib tiktoken \
  --encoder o200k_base \
  --ctx-limit 200000 > report.json

# Отчет для Gemini с использованием sentencepiece
listing-generator report ctx:onboarding \
  --lib sentencepiece \
  --encoder google/gemma-2-2b \
  --ctx-limit 1000000 > report.json

# Рендерим контекст с описанием текущей задачи
listing-generator render ctx:dev \
  --lib tiktoken --encoder cl100k_base --ctx-limit 128000 \
  --task "Реализовать кеширование результатов"

# Многострочная задача через stdin
echo -e "Задачи:\n- Исправить баг #123\n- Добавить тесты" | \
  listing-generator render ctx:dev --lib tiktoken --encoder cl100k_base --ctx-limit 128000 --task -

# Задача из файла
listing-generator render ctx:dev \
  --lib tiktoken --encoder cl100k_base --ctx-limit 128000 \
  --task @.current-task.txt

# Диагностика
listing-generator diag
listing-generator diag --rebuild-cache

# Списки
listing-generator list contexts
listing-generator list sections
listing-generator list tokenizer-libs
listing-generator list encoders --lib tiktoken
listing-generator list encoders --lib tokenizers
```

---

## Как именно LG рендерит документы

* Если **все файлы — Markdown/plain**, LG просто конкатенирует их содержимое.
* В остальных случаях:

  * **с code-fence** (по умолчанию): блоки по языкам, сгруппированные **по порядку следования**;
    внутри каждого блока — маркер файла `# —— FILE: path ——`, затем содержимое.
  * **без code-fence**: линейный документ с маркером перед каждым файлом.

Это делает промт **читаемым** для человека и удобным для агентов: видно, откуда какой фрагмент.

---

## Кэш и производительность

LG использует файловый кэш `.lg-cache`:

* **Processed-кэш** — результат работы адаптеров + их метаданные.
* **Raw/Processed tokens** — сохранённые подсчёты токенов (по модели/режиму).
* **Rendered tokens** — подсчёт финального документа («с клеем») и «sections-only».

Ключи кэша учитывают версию инструмента, fingerprint файла, конфиг адаптера, состав групп и т. п.
Управление: `listing-generator diag`, `listing-generator diag --rebuild-cache`. Можно отключить кэш через `LG_CACHE=0`.

---

## Практические советы по «плотным» контекстам

* **Держите секции мелкими и тематическими.** Лучше несколько секций, чем одна «всё обо всём».
* **Жёсткие `allow`-узлы** используйте там, где нужна полная предсказуемость содержимого.
* **Markdown-шаблоны** применяйте как «рамку» промта: краткая вводная, задачи, place-holders секций.
* **Режим `changes`** — лучший друг для патч-итераций и code-review через LLM.
* **Следите за долями** (`promptShare`/`ctxShare`) в `report`: это помогает «холдинг-кост» распределять.
* **Нормализуйте заголовки** (`max_heading_level`) — так удобнее читать длинные контексты.
* **Не тащите секреты.** Настройте `block` для артефактов/ключей/секретов/бинарников.

---

## Интеграция с IDE/плагинами

В большинстве случаев вы будете запускать LG **через интеграцию** (VS Code / JetBrains и т. п.).
Тем не менее, **вся логика отбора/шаблонов лежит в репозитории** (`lg-cfg/`), поэтому:

* ревьюить и эволюционировать правила просто (PR-ами),
* переносить удачные промты между проектами — тривиально,
* одна и та же конфигурация работает в CLI и в IDE.
<!-- lg:comment:end -->