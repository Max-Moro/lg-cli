# Неэффективный поиск nested literals в BlockInit

## Проблема

В `BlockInitProcessorBase._optimize_statement_recursive()` для каждого statement выполняется полный проход по всем профилям с tree-sitter query. Для statement с множеством дочерних узлов это приводит к избыточным tree-sitter запросам, большинство из которых возвращают пустой результат.

## Анализ текущего поведения

```python
# components/block_init.py (текущая версия)
class BlockInitProcessorBase(LiteralProcessor):
    def _optimize_statement_recursive(
        self,
        stmt_node: Node,
        doc: TreeSitterDocument,
        token_budget: int,
    ) -> str:
        """
        Recursively optimize nested literals within a statement (DFS).
        """
        stmt_text = doc.get_node_text(stmt_node)
        nested_literals = []

        def find_literals(node: Node, is_direct_child: bool = False):
            found_literal = False
            # ПРОБЛЕМА: Перебор ВСЕХ профилей для КАЖДОГО узла
            for profile in self.all_profiles:  # ~10-15 профилей
                try:
                    nodes = doc.query_nodes(profile.query, "lit")  # Tree-sitter query!
                    if node in nodes:
                        # Проверки...
                        if is_direct_child:
                            break

                        # Категоризация...
                        nested_literals.append(node)
                        found_literal = True
                        break
                except:
                    continue

            if not found_literal:
                # Рекурсивный спуск
                for child in node.children:
                    find_literals(child, is_direct_child=False)

        # Запуск с children stmt_node
        for child in stmt_node.children:
            find_literals(child, is_direct_child=True)

        # ... (дальнейшая обработка)
```

### Сложность

**Worst case**: Statement с 5 дочерними узлами, каждый имеет по 3 child → дерево из ~20 узлов
- **P** = 15 профилей
- **N** = 20 узлов в дереве
- **Запросов к tree-sitter**: P × N = **300 запросов**

Большинство запросов вернут пустой результат (профиль не матчится для данного node type).

## Решение: предвычисление literal nodes

Вместо выполнения tree-sitter query для каждого узла в дереве, выполнить все queries один раз для всего документа и сохранить координаты literal nodes в set.

```python
# components/block_init.py (исправленная версия)
class BlockInitProcessorBase(LiteralProcessor):
    """
    Base class for block initialization processors.

    Subclasses implement specific patterns (Java double-brace, Rust let-group).
    """

    def __init__(
        self,
        tokenizer,
        all_profiles: List[LiteralProfile],
        process_literal_callback: ProcessLiteralCallback,
        comment_formatter: CommentFormatter,
    ):
        """
        Initialize base processor.

        Args:
            tokenizer: Token counting service
            all_profiles: List of all literal profiles for nested literal detection
            process_literal_callback: Callback for processing nested literals
            comment_formatter: Comment syntax
        """
        self.tokenizer = tokenizer
        self.all_profiles = all_profiles
        self.process_literal_callback = process_literal_callback
        self.comment_formatter = comment_formatter
        self.source_text = None
        self.doc = None

        # Кэш для literal nodes координат (по документу)
        self._literal_nodes_cache: Optional[Dict[int, set]] = None

    def _get_all_literal_nodes(self, doc: TreeSitterDocument) -> set:
        """
        Collect all literal node coordinates in document.

        Caches results per document to avoid repeated tree-sitter queries.
        Uses document ID as cache key.

        Args:
            doc: Tree-sitter document

        Returns:
            Set of (start_byte, end_byte) tuples for all literal nodes
        """
        doc_id = id(doc)  # Используем id документа как ключ

        if self._literal_nodes_cache is None:
            self._literal_nodes_cache = {}

        if doc_id not in self._literal_nodes_cache:
            literal_coords = set()

            # Выполняем все профили ОДИН РАЗ для документа
            for profile in self.all_profiles:
                try:
                    nodes = doc.query_nodes(profile.query, "lit")
                    # Сохраняем координаты (start_byte, end_byte)
                    literal_coords.update(
                        (n.start_byte, n.end_byte) for n in nodes
                    )
                except:
                    continue

            self._literal_nodes_cache[doc_id] = literal_coords

        return self._literal_nodes_cache[doc_id]

    def _optimize_statement_recursive(
        self,
        stmt_node: Node,
        doc: TreeSitterDocument,
        token_budget: int,
    ) -> str:
        """
        Recursively optimize nested literals within a statement (DFS).

        Uses pre-computed literal nodes cache for O(1) lookups instead
        of repeated tree-sitter queries.

        Args:
            stmt_node: Statement node to optimize
            doc: Tree-sitter document
            token_budget: Token budget for nested optimization

        Returns:
            Optimized statement text
        """
        stmt_text = doc.get_node_text(stmt_node)
        nested_literals = []

        # Получить все literal координаты в документе (кэшировано)
        literal_coords = self._get_all_literal_nodes(doc)

        def find_literals(node: Node, is_direct_child: bool = False):
            coords = (node.start_byte, node.end_byte)

            # O(1) lookup вместо O(n_profiles) tree-sitter queries!
            if coords in literal_coords:
                # Найден literal node

                # Проверка на совпадение с stmt_node
                if node.start_byte == stmt_node.start_byte and node.end_byte == stmt_node.end_byte:
                    return  # Skip self

                # Skip direct children
                if is_direct_child:
                    return

                # Категоризация (нужно определить тип профиля)
                profile_type = self._get_profile_type_for_node(node, doc)
                category_map = {
                    'StringProfile': 'string',
                    'SequenceProfile': 'sequence',
                    'MappingProfile': 'mapping',
                    'FactoryProfile': 'factory',
                    'BlockInitProfile': 'block',
                }
                category = category_map.get(profile_type, '')

                if category in ["sequence", "mapping", "factory", "block"]:
                    nested_literals.append(node)
                    return  # Don't descend into literal

            # Рекурсивный спуск только если это НЕ literal
            for child in node.children:
                find_literals(child, is_direct_child=False)

        # Запуск с children stmt_node
        for child in stmt_node.children:
            find_literals(child, is_direct_child=True)

        if not nested_literals:
            return stmt_text

        # ... (дальнейшая обработка nested_literals - без изменений)

    def _get_profile_type_for_node(self, node: Node, doc: TreeSitterDocument) -> str:
        """
        Determine which profile type matched this node.

        Uses profile queries to categorize the node.

        Args:
            node: Literal node
            doc: Tree-sitter document

        Returns:
            Profile type name (e.g., "StringProfile", "SequenceProfile")
        """
        for profile in self.all_profiles:
            try:
                nodes = doc.query_nodes(profile.query, "lit")
                if node in nodes:
                    return type(profile).__name__
            except:
                continue

        return "UnknownProfile"
```

### Альтернатива: категоризация при предвычислении

Можно сразу сохранять не только координаты, но и тип профиля:

```python
def _get_all_literal_nodes_with_types(self, doc: TreeSitterDocument) -> Dict[tuple, str]:
    """
    Collect all literal node coordinates with profile types.

    Returns:
        Dict mapping (start_byte, end_byte) -> profile_type_name
    """
    doc_id = id(doc)

    if self._literal_nodes_cache is None:
        self._literal_nodes_cache = {}

    if doc_id not in self._literal_nodes_cache:
        literal_map = {}

        for profile in self.all_profiles:
            try:
                nodes = doc.query_nodes(profile.query, "lit")
                profile_type = type(profile).__name__

                for n in nodes:
                    coords = (n.start_byte, n.end_byte)
                    # Сохраняем тип профиля (первый matched выигрывает)
                    if coords not in literal_map:
                        literal_map[coords] = profile_type
            except:
                continue

        self._literal_nodes_cache[doc_id] = literal_map

    return self._literal_nodes_cache[doc_id]


def _optimize_statement_recursive(self, stmt_node: Node, doc: TreeSitterDocument, token_budget: int) -> str:
    literal_map = self._get_all_literal_nodes_with_types(doc)

    def find_literals(node: Node, is_direct_child: bool = False):
        coords = (node.start_byte, node.end_byte)

        if coords in literal_map:
            # Получаем тип профиля сразу из кэша!
            profile_type = literal_map[coords]

            # Проверки...
            if is_direct_child:
                return

            # Категоризация
            category_map = {
                'StringProfile': 'string',
                'SequenceProfile': 'sequence',
                'MappingProfile': 'mapping',
                'FactoryProfile': 'factory',
                'BlockInitProfile': 'block',
            }
            category = category_map.get(profile_type, '')

            if category in ["sequence", "mapping", "factory", "block"]:
                nested_literals.append(node)
                return

        # Рекурсивный спуск
        for child in node.children:
            find_literals(child, is_direct_child=False)
```

## Сравнение подходов

### Подход 1: Только координаты

**Плюсы**:
- Минимальная память
- Простая реализация

**Минусы**:
- Нужен дополнительный `_get_profile_type_for_node()` (еще один проход)

### Подход 2: Координаты + типы

**Плюсы**:
- Категоризация в O(1)
- Нет дополнительных запросов после кэширования

**Минусы**:
- Немного больше памяти

**Рекомендация**: Использовать **Подход 2** (координаты + типы) для максимальной производительности.

## Тестирование

```python
# tests/adapters/test_blockinit_caching.py
import pytest
from unittest.mock import Mock, patch
from lg.adapters.optimizations.literals.components.block_init import BlockInitProcessorBase


def test_literal_nodes_cached_per_document():
    """Literal nodes should be cached per document."""
    processor = BlockInitProcessorBase(
        tokenizer=Mock(),
        all_profiles=[Mock()],
        process_literal_callback=Mock(),
        comment_formatter=Mock(),
    )

    mock_doc1 = Mock()
    mock_doc2 = Mock()

    # First call for doc1
    with patch.object(mock_doc1, 'query_nodes', return_value=[]):
        cache1 = processor._get_all_literal_nodes_with_types(mock_doc1)

    # Second call for doc1 - should use cache
    with patch.object(mock_doc1, 'query_nodes', side_effect=AssertionError("Should not be called!")):
        cache1_again = processor._get_all_literal_nodes_with_types(mock_doc1)
        assert cache1 is cache1_again  # Same cache

    # First call for doc2 - different document
    with patch.object(mock_doc2, 'query_nodes', return_value=[]):
        cache2 = processor._get_all_literal_nodes_with_types(mock_doc2)

    # Different caches for different documents
    assert cache1 is not cache2


def test_tree_sitter_queries_minimized():
    """Tree-sitter queries should be minimized via caching."""
    profiles = [Mock(query="(string) @lit"), Mock(query="(array) @lit")]

    processor = BlockInitProcessorBase(
        tokenizer=Mock(),
        all_profiles=profiles,
        process_literal_callback=Mock(),
        comment_formatter=Mock(),
    )

    mock_doc = Mock()
    query_calls = []

    def track_query(query, capture):
        query_calls.append(query)
        return []

    mock_doc.query_nodes = track_query

    # First statement - populates cache
    processor._get_all_literal_nodes_with_types(mock_doc)

    # Should have queried all profiles once
    assert len(query_calls) == len(profiles)

    # Second statement - uses cache
    query_calls.clear()
    processor._get_all_literal_nodes_with_types(mock_doc)

    # Should NOT query again (cache hit)
    assert len(query_calls) == 0
```

## Ожидаемые выгоды

- Снижение количества tree-sitter queries с O(P × N) до O(P) для всего документа
- Ускорение обработки больших statement blocks (ожидаемое ускорение ~10-50x)
- O(1) lookup вместо O(n_profiles) для каждого узла
- Упрощение профилирования (меньше вызовов tree-sitter)
