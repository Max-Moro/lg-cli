# Вынос обработки строк из Pipeline

## Проблема

Метод `LiteralPipeline._process_literal` (строки 138-228) содержит специализированную логику для обработки строк, которая должна быть в отдельном компоненте:

- Вычисление overhead (должно быть в Selector)
- Обработка интерполяции (должно быть в InterpolationHandler)
- Создание псевдо-Selection для строк (специфичная логика)
- Условное ветвление для строк vs коллекций

Это нарушает принцип единой ответственности оркестратора — Pipeline должен только координировать, а не содержать детальную логику обработки.

Текущая оценка Pipeline: **7/10** — смешение ответственности.

## Целевые файлы

- `lg/adapters/optimizations/literals/processing/pipeline.py`
- `lg/adapters/optimizations/literals/components/__init__.py` (добавить новый компонент)
- `lg/adapters/optimizations/literals/components/string_processor.py` (создать новый файл)

## План рефакторинга

### Шаг 1: Создать StringLiteralProcessor компонент

Создать файл `lg/adapters/optimizations/literals/components/string_processor.py`:

```python
"""
String literal processor component.

Handles string literal optimization with interpolation support.
"""

from __future__ import annotations

from typing import Optional

from lg.adapters.optimizations.literals.patterns import StringProfile, TrimResult
from lg.adapters.optimizations.literals.processing.parser import LiteralParser
from lg.adapters.optimizations.literals.processing.selector import BudgetSelector
from lg.adapters.optimizations.literals.processing.formatter import ResultFormatter
from lg.adapters.optimizations.literals.utils.interpolation import InterpolationHandler
from lg.adapters.optimizations.literals.utils.element_parser import Element


class StringLiteralProcessor:
    """
    Processes string literals with interpolation support.

    Handles:
    - Truncation to fit token budget
    - Interpolation boundary adjustment
    - Inline placeholder formatting
    """

    def __init__(
        self,
        parser: LiteralParser,
        selector: BudgetSelector,
        formatter: ResultFormatter,
        interpolation: InterpolationHandler,
    ):
        """
        Initialize processor.

        Args:
            parser: LiteralParser for parsing structure
            selector: BudgetSelector for overhead calculation
            formatter: ResultFormatter for final formatting
            interpolation: InterpolationHandler for interpolation support
        """
        self.parser = parser
        self.selector = selector
        self.formatter = formatter
        self.interpolation = interpolation

    def can_handle(
        self,
        profile,
        node,
        doc,
    ) -> bool:
        """
        Check if this component is applicable.

        Args:
            profile: Literal profile
            node: Tree-sitter node (unused, kept for interface consistency)
            doc: Tree-sitter document (unused, kept for interface consistency)

        Returns:
            True if this component should handle the literal
        """
        return isinstance(profile, StringProfile)

    def process(
        self,
        node,
        doc,
        source_text: str,
        profile: StringProfile,
        budget: int,
    ) -> Optional[TrimResult]:
        """
        Full autonomous processing of string literal.

        Args:
            node: Tree-sitter node
            doc: Tree-sitter document
            source_text: Full source text
            profile: StringProfile
            budget: Token budget

        Returns:
            TrimResult if optimization applied, None otherwise
        """
        # Parse structure
        parsed = self.parser.parse_from_node(node, doc, source_text, profile)

        if not parsed or parsed.original_tokens <= budget:
            return None

        # Calculate overhead
        placeholder = "…"
        overhead = self.selector.calculate_overhead(
            parsed.opening, parsed.closing, placeholder,
            parsed.is_multiline, parsed.element_indent
        )
        content_budget = max(1, budget - overhead)

        # Truncate content
        truncated = self.selector.tokenizer.truncate_to_tokens(
            parsed.content, content_budget
        )

        if len(truncated) >= len(parsed.content):
            return None

        # Adjust for interpolation
        markers = self.interpolation.get_active_markers(
            profile, parsed.opening, parsed.content
        )
        if markers:
            truncated = self.interpolation.adjust_truncation(
                truncated, parsed.content, markers
            )

        # Create pseudo-selection for formatter
        from lg.adapters.optimizations.literals.processing.selector import Selection

        kept_element = Element(
            text=truncated,
            raw_text=truncated,
            start_offset=0,
            end_offset=len(truncated),
        )
        removed_element = Element(
            text="...",
            raw_text="...",
            start_offset=0,
            end_offset=0
        )

        selection = Selection(
            kept_elements=[kept_element],
            removed_elements=[removed_element],
            total_count=1,
            tokens_kept=self.selector.tokenizer.count_text_cached(truncated),
            tokens_removed=parsed.original_tokens - self.selector.tokenizer.count_text_cached(truncated),
        )

        # Format result
        formatted = self.formatter.format(parsed, selection)

        # Build final result
        trimmed_tokens = self.selector.tokenizer.count_text_cached(formatted.text)

        return TrimResult(
            trimmed_text=formatted.text,
            original_tokens=parsed.original_tokens,
            trimmed_tokens=trimmed_tokens,
            saved_tokens=parsed.original_tokens - trimmed_tokens,
            elements_kept=1,
            elements_removed=0,
            comment_text=formatted.comment,
            comment_position=formatted.comment_byte,
        )
```

### Шаг 2: Зарегистрировать компонент в Pipeline

Обновить `LiteralPipeline.__init__` в `pipeline.py`:

```python
def __init__(self, cfg: LiteralConfig, adapter):
    """Initialize pipeline."""
    self.cfg = cfg
    self.adapter = cast(CodeAdapter, adapter)

    # Get descriptor from adapter
    self.descriptor = self.adapter.create_literal_descriptor()

    # Get comment style from adapter
    comment_style: tuple[str, tuple[str, str]] = cast(
        tuple[str, tuple[str, str]],
        self.adapter.get_comment_style()[:2]
    )
    self.single_comment = comment_style[0]
    self.block_comment = comment_style[1]

    # Cache parsers for different patterns
    self._parsers: dict[str, ElementParser] = {}

    # Universal processing stages
    self.literal_parser = LiteralParser(self.adapter.tokenizer)
    self.selector = BudgetSelector(self.adapter.tokenizer)
    self.formatter = ResultFormatter(self.adapter.tokenizer, comment_style)
    self.interpolation = InterpolationHandler()

    # Special components (ordered by priority)
    self.special_components = [
        StringLiteralProcessor(
            self.literal_parser,
            self.selector,
            self.formatter,
            self.interpolation,
        ),
        ASTSequenceProcessor(
            self.adapter.tokenizer,
            [p for p in self.descriptor.profiles if isinstance(p, StringProfile)]
        ),
        BlockInitProcessor(
            self.adapter.tokenizer,
            self.descriptor.profiles,
            self._process_literal,
            comment_style
        ),
    ]
```

### Шаг 3: Упростить _process_literal в Pipeline

Убрать специальную обработку строк из `_process_literal`:

```python
def _process_literal(
    self,
    node,
    doc,
    source_text: str,
    profile: LiteralProfile,
    budget: int
) -> Optional[TrimResult]:
    """
    Unified literal processing entry point.

    Called both from the pipeline and recursively from components.
    Only coordinates stages and components - no detailed logic.
    """
    # Try special components first (in priority order)
    for component in self.special_components:
        if component.can_handle(profile, node, doc):
            return component.process(
                node,
                doc,
                source_text,
                profile,
                budget
            )

    # Standard path through stages (only for collections)
    parsed = self.literal_parser.parse_from_node(
        node, doc, source_text, profile
    )

    if not parsed or parsed.original_tokens <= budget:
        return None

    # Calculate overhead
    placeholder = parsed.profile.placeholder_template
    overhead = self.selector.calculate_overhead(
        parsed.opening, parsed.closing, placeholder,
        parsed.is_multiline, parsed.element_indent
    )
    content_budget = max(1, budget - overhead)

    # Collection processing: parse + DFS selection
    parser = self._get_parser_for_profile(parsed.profile)
    elements = parser.parse(parsed.content)

    if not elements:
        return None

    # Select elements with DFS
    selection = self.selector.select_dfs(
        elements, content_budget,
        parser,
        min_keep=parsed.profile.min_elements,
        tuple_size=parsed.profile.tuple_size if isinstance(parsed.profile, FactoryProfile) else 1,
        preserve_top_level_keys=parsed.profile.preserve_all_keys if isinstance(parsed.profile, MappingProfile) else False,
    )

    if not selection.has_removals:
        return None

    # Format result
    formatted = self.formatter.format_dfs(parsed, selection, parser)

    # Build final result
    trimmed_tokens = self.adapter.tokenizer.count_text_cached(formatted.text)

    return TrimResult(
        trimmed_text=formatted.text,
        original_tokens=parsed.original_tokens,
        trimmed_tokens=trimmed_tokens,
        saved_tokens=parsed.original_tokens - trimmed_tokens,
        elements_kept=selection.kept_count,
        elements_removed=selection.removed_count,
        comment_text=formatted.comment,
        comment_position=formatted.comment_byte,
    )
```

### Шаг 4: Обновить экспорты

Обновить `lg/adapters/optimizations/literals/components/__init__.py`:

```python
"""
Components for literals optimization.
"""

from .ast_sequence import ASTSequenceProcessor
from .block_init import BlockInitProcessor
from .string_processor import StringLiteralProcessor

__all__ = ['ASTSequenceProcessor', 'BlockInitProcessor', 'StringLiteralProcessor']
```

## Критерии успешности

После рефакторинга:

1. **Четкое разделение ответственности**:
   - Pipeline не содержит специализированной логики обработки строк
   - StringLiteralProcessor автономно обрабатывает строки
   - Логика интерполяции инкапсулирована в компоненте

2. **Размер методов**:
   - `Pipeline._process_literal`: не более 80 строк (было ~90)
   - `StringLiteralProcessor.process`: не более 70 строк

3. **Расширяемость**:
   - Легко добавить специфичную логику для строк в компоненте
   - Pipeline остается чистым оркестратором

## Проверка результата

1. Запустить golden tests для всех языков:
   ```bash
   ./scripts/test_adapters.sh literals all
   ```

2. Особое внимание к языкам с интерполяцией:
   - Python (f-strings)
   - JavaScript/TypeScript (template strings)
   - Kotlin (string templates)
   - Scala (interpolated strings)

3. Убедиться, что интерполяция обрабатывается корректно

## Ожидаемый результат

- ✅ Все golden tests проходят без изменений
- ✅ Pipeline чище и проще
- ✅ Логика обработки строк инкапсулирована в компоненте
- ✅ Оценка Pipeline повышается с 7/10 до 9/10
