# Дорожная карта: Literal Optimization (целевое состояние «v2»)

> Рабочий код перерабатывается в текущем каталоге. Параллельных веток и совместимости со старой моделью не будет.

## Принципы миграции

1. **Атомарность**: Каждый подэтап - минимальное изменение с полной проверкой тестов
2. **Нулевые регрессии**: После каждого подэтапа все 100 тестов должны проходить
3. **Постепенность**: Миграция языков идет группами по 1-3 языка
4. **Backward compatibility**: До полной миграции ядра сохраняется совместимость через конвертацию

---

## Этапы

### ✅ Этап 1: Новая модель паттернов и дескриптора
Заменён плоский `LiteralPattern` на типизированную иерархию профилей (StringProfile, SequenceProfile, MappingProfile, FactoryProfile, BlockInitProfile).

### ✅ Этап 2: Ввод processing/pipeline.py
Создан `processing/pipeline.py` с двухпроходной оркестрацией. Удалён `core.py`.

### ✅ Этап 3: Вынос парсинга
Создан `processing/parser.py` (LiteralParser). Старый `parser.py` → `element_parser.py`.

### ✅ Этап 4: Вынос бюджетного выбора
Создан `processing/selector.py` (Selection/DFSSelection). Удалён старый `selector.py`.

### ✅ Этап 5: Вынос форматирования
Создан `processing/formatter.py` (ResultFormatter). Удалён старый `formatter.py`.

### ✅ Этап 6: Адаптация ядра для работы с профилями
Полный переход на профили (5 подэтапов: parser, selector, formatter, backward compat, LiteralPattern). Удалено ~555 строк legacy кода. Перемещены `LiteralCategory` и `PlaceholderPosition` в `patterns.py`.

### ✅ Этап 6.1: Рефакторинг модели профилей (вклинившийся)
Улучшение архитектуры модели после выявления проблем при работе с профилями.

**Решенные проблемы**:
- Проблема №1: Избыточное использование hasattr/getattr (64+ вызова)
  * Создан базовый класс `LiteralProfile` с общими атрибутами
  * Специализированные профили наследуются от базового
  * Заменены hasattr/getattr на прямой доступ и isinstance проверки

- Проблема №2: Фрагментация модели на 3 модуля
  * Объединены `categories.py` и `patterns.py` в единый `patterns.py`
  * Удален `categories.py` (ParsedLiteral, TrimResult перенесены)
  * Осталось 2 модуля: patterns.py (модель) и descriptor.py (языковые дескрипторы)

- Проблема №3: Дублирование LiteralCategory enum
  * Удален `LiteralCategory` enum полностью
  * Удалено поле `category` из `ParsedLiteral`
  * Все проверки заменены на `isinstance(profile, ProfileType)`
  * Генерация комментариев через интроспекцию типа профиля

### ✅ Этап 6.2: Удаление поля priority (вклинившийся)
Полное удаление мертвого кода после эмпирической проверки.

**Обоснование удаления**:
- После разделения на типизированные списки (string_profiles, sequence_profiles, etc.) priority потерял смысл
- Эмпирическая проверка показала: Tree-sitter queries не пересекаются внутри категорий
- Разные node types и предикаты уже исключают коллизии
- Порядок в списке естественным образом определяет приоритет проверки

**Выполненные изменения**:
- Удалено поле `priority: int = 0` из базового класса `LiteralProfile`
- Удалены все присвоения `priority=N` из 10 языковых дескрипторов
- Обновлены комментарии в дескрипторах (убраны упоминания priority)
- Никакой логики сортировки по priority не обнаружено (уже не использовалось)

**Результат**: 100/100 тестов ✅, голдены без изменений, ~50 строк удалено

#### ✅ Этап 6.3: Персонализированная обработка профилей (вклинившийся)
Устранение избыточного паттерна "склеивание-расклеивание" через прямую работу с типизированными списками профилей.

**Проблема**:
- Профили склеивались в `all_profiles` / `profile_groups`, теряя типовую информацию
- Затем код "расклеивал" через `isinstance` или строковые метки типов (`profile_type: str`)
- Терялась типобезопасность, добавлялся runtime overhead

**Решение (только в pipeline.py)**:
- Убрано склеивание профилей - прямая итерация по типизированным спискам
- Общая логика пайплайна вынесена в переиспользуемый `_process_profile()`
- Удалён dispatcher `_process_collection_node()` со строковыми метками
- Специализированные процессоры получают профили нужного типа напрямую

**Выполненные изменения**:
- `pipeline.py`: персонализированная обработка через `_process_profile()`, убраны все isinstance для dispatch
- `formatter.py`, `handler.py`: микро-оптимизация импортов (без структурных изменений)

**Результат**: 100/100 тестов ✅, голдены без изменений, улучшена структура pipeline

### Этап 7: Компонент Interpolation
- Создать `components/interpolation.py`: правила границ/делимитеров интерполяции, корректировка тримминга строк
- Удалить дублирующие проверки интерполяции из parser/formatter и из `handler.py`; подключить через pipeline
- **Критерий**: Все 100 тестов проходят

### Этап 8: Компонент AST sequence
- Создать `components/ast_sequence.py` для последовательностей без разделителей (конкатенации строк и т.п.)
- Удалить AST-специфичные костыли из `handler.py`; использовать компонент через pipeline
- **Критерий**: Все 100 тестов проходят

### Этап 9: Компонент Block init
- Создать `components/block_init.py` с API для imperative инициализаций (double-brace Java, Rust HashMap chain)
- Удалить из старого `block_init.py` размещённые эвристики; подключить новый компонент из pipeline
- **Критерий**: Все 100 тестов проходят

### Этап 10: Компонент Placeholder/Comment
- Создать `components/placeholder.py` для единого формирования плейсхолдеров/комментариев
- Удалить логику вставки комментариев из formatter и `handler.py`; оставить вызовы компонента
- **Критерий**: Все 100 тестов проходят

### Этап 11: Компонент Budgeting
- Создать `components/budgeting.py` с политиками приоритетов/лимитов
- Убрать бюджетные решения из formatter/parser; pipeline передает бюджет в selector/компонент
- **Критерий**: Все 100 тестов проходят

### Этап 12: Полное отключение наследия handler

**Цель**: Удалить последний legacy файл и убедиться что pipeline содержит только высокоуровневую оркестрацию.

- **УДАЛИТЬ** `handler.py` (единственный оставшийся legacy файл)
- Обновить экспорты `lg/adapters/optimizations/literals/__init__.py` на `processing/` + `components/`
- Убедиться что в `pipeline.py` осталась **только высокоуровневая оркестрация**:
  - Управление двухпроходной логикой
  - Вызовы компонентов из `processing/` и `components/`
  - Никакой детальной логики парсинга/форматирования/бюджетирования
- Проверить, что адаптеры используют только pipeline/processing/компоненты
- **Критерий**: Все 100 тестов проходят

### Этап 13: Разгрузка языковых хаков
- В языковых `literals.py` убрать специальные ветки, которые покрываются компонентами (interpolation, ast_sequence, block_init)
- Оставить только декларативные профили/флаги в дескрипторах
- **Критерий**: Все 100 тестов проходят

### Этап 14: Финальная чистка структуры
- Убрать временные типы/шунты, оставить минимально необходимый публичный API (patterns/descriptor/pipeline/компоненты)
- Обновить `__init__.py` в `components/` и `processing/` для явных экспортов
- Финальный прогон всех тестов
- **Критерий**: Все 100 тестов проходят

---

## Текущий статус

- **Ветка**: `literals-v2`
- **Текущий этап**: ✅ Этапы 1-6.3 завершены, готов к Этапу 7
- **Последний прогон**: 100/100 тестов ✅
- **Последний коммит**: (pending) "Stage 6.3: Eliminate dispatch pattern via personalized profile processing"
- **Структура**:
  - `processing/`: parser ✅, selector ✅, formatter ✅, pipeline ✅ (персонализированная обработка)
  - `patterns.py`: Модель данных с иерархией профилей ✅ (базовый LiteralProfile + 5 специализированных)
  - `descriptor.py`: Языковые дескрипторы ✅
  - Удалено: core.py, старые selector.py/formatter.py, categories.py, LiteralPattern, LiteralCategory, priority, dispatch pattern (~800 строк)
  - Legacy: handler.py (удаляется на Этапе 12), block_init.py (рефакторится на Этапе 9)
